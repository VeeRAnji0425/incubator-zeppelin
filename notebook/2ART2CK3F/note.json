{
  "paragraphs": [
    {
      "text": "%md\n\nReading data from Cassandra\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432125137469_650840895",
      "id": "20150520-143217_474596748",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch1\u003eReading data from Cassandra\u003c/h1\u003e\n"
      },
      "dateCreated": "May 20, 2015 2:32:17 PM",
      "dateStarted": "May 20, 2015 2:33:38 PM",
      "dateFinished": "May 20, 2015 2:33:39 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n**Many ways to read data from Cassandra**:\n\n1. using plain **CassandraRDD[CassandraRow]**\n2. converting **CassandraRow** columns into **tuples**\n3. using **Scala case classes** with the integrated **object mapper**",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "tableHide": false,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432125218563_-1408664128",
      "id": "20150520-143338_1132207280",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003e\u003cstrong\u003eMany ways to read data from Cassandra\u003c/strong\u003e:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eusing plain \u003cstrong\u003eCassandraRDD[CassandraRow]\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003econverting \u003cstrong\u003eCassandraRow\u003c/strong\u003e columns into \u003cstrong\u003etuples\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eusing \u003cstrong\u003eScala case classes\u003c/strong\u003e with the integrated \u003cstrong\u003eobject mapper\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "May 20, 2015 2:33:38 PM",
      "dateStarted": "May 20, 2015 2:35:15 PM",
      "dateFinished": "May 20, 2015 2:35:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Reset table display",
      "text": "import org.apache.spark.rdd.RDD\n\nvar data:RDD[(Int,Double)] \u003d sc.parallelize(Nil)",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "tableHide": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432125938553_1725190640",
      "id": "20150520-144538_434871993",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.rdd.RDD\ndata: org.apache.spark.rdd.RDD[(Int, Double)] \u003d ParallelCollectionRDD[94] at parallelize at \u003cconsole\u003e:52\n"
      },
      "dateCreated": "May 20, 2015 2:45:38 PM",
      "dateStarted": "Jul 20, 2015 3:42:52 PM",
      "dateFinished": "Jul 20, 2015 3:42:52 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Reading data using plain CassandraRow",
      "text": "import org.apache.spark.SparkContext._\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.rdd.CassandraRDD\nimport org.apache.spark.{SparkConf, SparkContext}\n\n\ndata \u003d sc.cassandraTable(\"spark_demo\", \"us_unemployment_stats\").\n    map( row \u003d\u003e (row.getInt(\"year\"),row.getDouble(\"unemployed_percentage_to_labor\")))",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "tableHide": true,
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432125315541_2118499250",
      "id": "20150520-143515_1959047089",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.SparkContext._\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.rdd.CassandraRDD\nimport org.apache.spark.{SparkConf, SparkContext}\ndata: org.apache.spark.rdd.RDD[(Int, Double)] \u003d MapPartitionsRDD[96] at map at \u003cconsole\u003e:64\n"
      },
      "dateCreated": "May 20, 2015 2:35:15 PM",
      "dateStarted": "Jul 20, 2015 3:43:09 PM",
      "dateFinished": "Jul 20, 2015 3:43:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "read data using scala tuples",
      "text": "data \u003d sc.cassandraTable(\"spark_demo\", \"us_unemployment_stats\").\n    select(\"year\", \"unemployed_percentage_to_labor\").\n    as((_: Int, _: Double)).\n    sortByKey()",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432126014638_1008677629",
      "id": "20150520-144654_1348217378",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "data: org.apache.spark.rdd.RDD[(Int, Double)] \u003d ShuffledRDD[26] at sortByKey at \u003cconsole\u003e:52\n"
      },
      "dateCreated": "May 20, 2015 2:46:54 PM",
      "dateStarted": "Jun 15, 2015 1:40:37 PM",
      "dateFinished": "Jun 15, 2015 1:40:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Read data using scala case class",
      "text": "case class UsUnemploymentRate(year: Int, unemployedPercentageToLabor: Double)\n\ndata \u003d sc.cassandraTable[UsUnemploymentRate](\"spark_demo\", \"us_unemployment_stats\").\n    sortBy(bean \u003d\u003e bean.year,true,1).\n    map(bean \u003d\u003e (bean.year,bean.unemployedPercentageToLabor))",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "tableHide": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1433842506554_-1567680288",
      "id": "20150609-113506_374130940",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "defined class UsUnemploymentRate\ndata: org.apache.spark.rdd.RDD[(Int, Double)] \u003d MappedRDD[23] at map at \u003cconsole\u003e:40\n"
      },
      "dateCreated": "Jun 9, 2015 11:35:06 AM",
      "dateStarted": "Jun 17, 2015 10:31:25 AM",
      "dateFinished": "Jun 17, 2015 10:31:27 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Read data using sparkSQL",
      "text": "import org.apache.spark.sql.cassandra.CassandraSQLContext\n\nval cc \u003d new CassandraSQLContext(sc)\n\nval row \u003d cc.cassandraSql(s\"SELECT year,unemployed_percentage_to_labor \" +\n                                     s\"FROM spark_demo.us_unemployment_stats WHERE unemployed_percentage_to_labor \u003e 8 \" +\n                                     s\"ORDER BY year DESC\")\ndata \u003d row.\n    map(row \u003d\u003e (row.getInt(0),row.getDouble(1))).\n    sortBy{case(year,_) \u003d\u003e year}\n",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "tableHide": false,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432126280851_1108867753",
      "id": "20150520-145120_1566314701",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.sql.cassandra.CassandraSQLContext\ncc: org.apache.spark.sql.cassandra.CassandraSQLContext \u003d org.apache.spark.sql.cassandra.CassandraSQLContext@5afaded9\nrow: org.apache.spark.sql.DataFrame \u003d [year: int, unemployed_percentage_to_labor: double]\ndata: org.apache.spark.rdd.RDD[(Int, Double)] \u003d MapPartitionsRDD[112] at sortBy at \u003cconsole\u003e:68\n"
      },
      "dateCreated": "May 20, 2015 2:51:20 PM",
      "dateStarted": "Jul 20, 2015 3:43:47 PM",
      "dateFinished": "Jul 20, 2015 3:43:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "data.display(\"Year\",\"Unemployment Percentage\")",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "Year",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "Unemployment Percentage",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "Year",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432125489739_1001031913",
      "id": "20150520-143809_1476305925",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "Year\tUnemployment Percentage\n1941\t9.9\n1975\t8.5\n1982\t9.7\n1983\t9.6\n2009\t9.3\n2010\t9.6\n"
      },
      "dateCreated": "May 20, 2015 2:38:09 PM",
      "dateStarted": "Jul 20, 2015 3:43:51 PM",
      "dateFinished": "Jul 20, 2015 3:43:52 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%cassandra\n\nSELECT * FROM spark_demo.twitter_stream;",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "keyword",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "interval",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "keyword",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "interval",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1432125656671_-542517733",
      "id": "20150520-144056_1766733826",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "keyword\tinterval\tcount\nlove\t2015-07-20 13:49:00\t3\nlove\t2015-07-20 13:48:55\t2\nlove\t2015-07-20 13:48:50\t4\nlove\t2015-07-20 13:48:45\t1\nlove\t2015-07-20 13:48:40\t6\nlove\t2015-07-20 13:48:35\t3\nlove\t2015-07-20 13:48:30\t4\nlove\t2015-07-20 13:48:25\t2\njoy\t2015-07-20 13:49:00\t1\njoy\t2015-07-20 13:48:55\t1\njoy\t2015-07-20 13:48:50\t2\njoy\t2015-07-20 13:48:45\t1\njoy\t2015-07-20 13:48:40\t1\njoy\t2015-07-20 13:48:35\t1\njoy\t2015-07-20 13:48:30\t1\nsadness\t2015-07-20 13:48:55\t2\nsadness\t2015-07-20 13:48:45\t3\nsadness\t2015-07-20 13:48:35\t1\n"
      },
      "dateCreated": "May 20, 2015 2:40:56 PM",
      "dateStarted": "Jul 20, 2015 3:49:03 PM",
      "dateFinished": "Jul 20, 2015 3:49:03 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1437400112265_-103467212",
      "id": "20150720-154832_1356318778",
      "dateCreated": "Jul 20, 2015 3:48:32 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "02-Reading Data from Cassandra",
  "id": "2ART2CK3F",
  "angularObjects": {
    "2ARKVF46K": [],
    "2ANYRH787": [],
    "2AQBHNCAB": [],
    "2ANRWDJG1": [],
    "2ANNAMCUB": [],
    "2ARR8D6R9": [],
    "2AQAS485Z": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}